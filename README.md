# LLM Security Gateway

**Sistema de autenticaciÃ³n y autorizaciÃ³n centralizado para modelos de lenguaje (LLM) desplegados localmente.**

Este mÃ³dulo actÃºa como gateway de seguridad que valida y autoriza las aplicaciones antes de permitirles consumir modelos LLM locales. Proporciona autenticaciÃ³n basada en roles, gestiÃ³n de tokens JWT con TTL diferenciado y validaciÃ³n mediante endpoints para integraciÃ³n con proxies inversos como NGINX.

---

## ğŸ¯ Objetivo

Proveer una capa de seguridad robusta que:
- **Autentica** aplicaciones y agentes antes de acceder a modelos LLM
- **Autoriza** acceso basado en roles con diferentes niveles de privilegios
- **Gestiona** tokens JWT con tiempo de vida (TTL) personalizado por rol
- **Valida** requests en tiempo real para proxies como NGINX
- **Protege** recursos computacionales costosos (modelos LLM) de accesos no autorizados

---

## ğŸ—ï¸ Arquitectura de la SoluciÃ³n

### Diagrama de Componentes

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     CLIENTES / CONSUMIDORES      â”‚
                    â”‚  (Agentes IA, Apps, Usuarios)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â”‚ 
                                     â”‚ (login , requests)
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                  â”‚
                    â”‚        NGINX / PROXY             â”‚
                    â”‚   (Reverse Proxy Gateway)        â”‚
                    â”‚     ğŸ”’ Punto de entrada Ãºnico    â”‚
                    â”‚                                  â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚  Login: proxy_pass a Auth  â”‚  â”‚
                    â”‚  â”‚  Requests: auth_request +  â”‚  â”‚
                    â”‚  â”‚            proxy_pass LLM  â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                          â”‚                      â”‚
                  Proxy/Subrequest               â”‚ Proxy Pass
                  (Auth/ValidaciÃ³n)              â”‚ (a LLM Server)
                          â”‚                      â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
              â”‚                      â”‚           â”‚
              â”‚  LLM Security API    â”‚           â”‚
              â”‚  (Auth Backend)      â”‚           â”‚
              â”‚   Port: 9000         â”‚           â”‚
              â”‚                      â”‚           â”‚
              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚           â”‚
              â”‚  â”‚ POST /llm/loginâ”‚  â”‚           â”‚
              â”‚  â”‚ POST /login    â”‚  â”‚           â”‚
              â”‚  â”‚ POST /validate â”‚  â”‚           â”‚
              â”‚  â”‚                â”‚  â”‚           â”‚
              â”‚  â”‚ Token Cache    â”‚  â”‚           â”‚
              â”‚  â”‚ Role RBAC      â”‚  â”‚           â”‚
              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚           â”‚
              â”‚                      â”‚           â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                                                 â”‚
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚                                  â”‚
                                â”‚         LLM SERVER(S)            â”‚
                                â”‚   (Ollama, vLLM, LocalAI)        â”‚
                                â”‚                                  â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Flujos de Secuencia

#### **Flujo 1: Login / AutenticaciÃ³n (obtener token)**

```sequence
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cliente â”‚       â”‚  NGINX  â”‚       â”‚ Auth API â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                 â”‚                  â”‚
     â”‚  1. POST /auth/llm/login           â”‚
     â”‚     Basic Auth                     â”‚
     â”‚     (username:password)            â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚
     â”‚                 â”‚                  â”‚
     â”‚                 â”‚  2. proxy_pass   â”‚
     â”‚                 â”‚     (forward)    â”‚
     â”‚                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
     â”‚                 â”‚                  â”‚
     â”‚                 â”‚                  â”‚ 3. Verifica:
     â”‚                 â”‚                  â”‚    â€¢ Credenciales
     â”‚                 â”‚                  â”‚    â€¢ Role vÃ¡lido
     â”‚                 â”‚                  â”‚ 4. Genera JWT
     â”‚                 â”‚                  â”‚ 5. Cache token
     â”‚                 â”‚                  â”‚
     â”‚                 â”‚  6. 200 OK       â”‚
     â”‚                 â”‚     {token, exp} â”‚
     â”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                 â”‚                  â”‚
     â”‚  7. 200 OK      â”‚                  â”‚
     â”‚     Token JWT   â”‚                  â”‚
     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
     â”‚                 â”‚                  â”‚
     â”‚ âœ… Cliente guarda token            â”‚
     â”‚                 â”‚                  â”‚
```

#### **Flujo 2: Request a LLM con Token VÃ¡lido**

```sequence
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cliente â”‚       â”‚  NGINX  â”‚       â”‚ Auth API â”‚       â”‚ LLM Serverâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                 â”‚                  â”‚                  â”‚
     â”‚  1. GET /llm/chat                  â”‚                  â”‚
     â”‚     Bearer: <token>                â”‚                  â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚                  â”‚
     â”‚                 â”‚                  â”‚                  â”‚
     â”‚                 â”‚  2. INTERCEPTA   â”‚                  â”‚
     â”‚                 â”‚     auth_request â”‚                  â”‚
     â”‚                 â”‚     (subrequest) â”‚                  â”‚
     â”‚                 â”‚                  â”‚                  â”‚
     â”‚                 â”‚  3. POST /validate                  â”‚
     â”‚                 â”‚     {token: "..."}                  â”‚
     â”‚                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚
     â”‚                 â”‚                  â”‚                  â”‚
     â”‚                 â”‚                  â”‚ 4. Verifica:     â”‚
     â”‚                 â”‚                  â”‚    â€¢ JWT vÃ¡lido  â”‚
     â”‚                 â”‚                  â”‚    â€¢ En cache    â”‚
     â”‚                 â”‚                  â”‚    â€¢ No expirado â”‚
     â”‚                 â”‚                  â”‚                  â”‚
     â”‚                 â”‚  5. 200 OK       â”‚                  â”‚
     â”‚                 â”‚     {valid: true}â”‚                  â”‚
     â”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
     â”‚                 â”‚                  â”‚                  â”‚
     â”‚                 â”‚  6. proxy_pass (forward request)    â”‚
     â”‚                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
     â”‚                 â”‚                  â”‚                  â”‚
     â”‚                 â”‚                  â”‚   7. Procesa LLM â”‚
     â”‚                 â”‚                  â”‚                  â”‚
     â”‚                 â”‚  8. LLM Response                    â”‚
     â”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                 â”‚                  â”‚                  â”‚
     â”‚  9. Response    â”‚                  â”‚                  â”‚
     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚                  â”‚
     â”‚                 â”‚                  â”‚                  â”‚
```

#### **Flujo 3: Request con Token InvÃ¡lido/Expirado**

```sequence
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cliente â”‚       â”‚  NGINX  â”‚       â”‚ Auth API â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                 â”‚                  â”‚
     â”‚  1. GET /llm/chat                  â”‚
     â”‚     Bearer: <bad_token>            â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚
     â”‚                 â”‚                  â”‚
     â”‚                 â”‚  2. auth_request â”‚
     â”‚                 â”‚     POST /validate                  
     â”‚                 â”‚     {token: "bad"}                  
     â”‚                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
     â”‚                 â”‚                  â”‚
     â”‚                 â”‚                  â”‚ 3. Token:
     â”‚                 â”‚                  â”‚    â€¢ InvÃ¡lido
     â”‚                 â”‚                  â”‚    â€¢ O expirado
     â”‚                 â”‚                  â”‚    â€¢ No en cache
     â”‚                 â”‚                  â”‚
     â”‚                 â”‚  4. 401          â”‚
     â”‚                 â”‚     {valid: false}
     â”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                 â”‚                  â”‚
     â”‚  5. 401         â”‚                  â”‚
     â”‚  Unauthorized   â”‚                  â”‚
     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
     â”‚                 â”‚                  â”‚
     â”‚ âŒ NO llega al LLM Server          â”‚
     â”‚ âš ï¸  Debe hacer login nuevamente    â”‚
     â”‚                 â”‚                  â”‚
```

---

### Notas de Arquitectura

**ğŸ”‘ Puntos Clave:**

1. **NGINX como Gateway Ãšnico**: Todos los clientes se conectan Ãºnicamente a NGINX, nunca directamente al Auth API o LLM Server

2. **InterceptaciÃ³n Transparente**: NGINX usa `auth_request` para validar cada peticiÃ³n antes de hacer proxy al LLM

3. **ValidaciÃ³n Centralizada**: Auth API solo expone `/validate` para NGINX, no para clientes directos

4. **ProtecciÃ³n del LLM**: El servidor LLM nunca estÃ¡ expuesto directamente, solo accesible vÃ­a NGINX con token vÃ¡lido

5. **SeparaciÃ³n de Responsabilidades**:
   - **NGINX**: Gateway, routing, validaciÃ³n de requests
   - **Auth API**: AutenticaciÃ³n, generaciÃ³n/validaciÃ³n de tokens
   - **LLM Server**: Procesamiento de modelos (protegido)

---

### ğŸ”Œ SDK para Clientes

**Para facilitar la integraciÃ³n con este sistema de seguridad, existe un SDK oficial:**

ğŸ“¦ **[LLM Architecture SDK](https://github.com/Root1V/llm-arch-sdk.git)**

Este SDK maneja automÃ¡ticamente:
- âœ… **AutenticaciÃ³n** con el Auth Gateway
- âœ… **GestiÃ³n de tokens JWT** (obtenciÃ³n, renovaciÃ³n, cachÃ©)
- âœ… **RenovaciÃ³n automÃ¡tica** de tokens expirados
- âœ… **Manejo de errores** de autenticaciÃ³n
- âœ… **ConexiÃ³n simplificada** al LLM Server vÃ­a NGINX

**InstalaciÃ³n:**
```bash
pip install git+https://github.com/Root1V/llm-arch-sdk.git
```

**ğŸ“– Ejemplo de Uso:**

Para ver ejemplos completos de integraciÃ³n y uso del SDK, consulta el proyecto de ejemplo:

ğŸ‘‰ **[LLM SDK Client - Proyecto de Ejemplo](https://github.com/Root1V/llm-sdk-client.git)**

Este repositorio contiene ejemplos prÃ¡cticos de:
- ConfiguraciÃ³n del cliente con el SDK
- AutenticaciÃ³n y gestiÃ³n de tokens
- Diferentes patrones de uso (agentes, usuarios, monitoring)
- Manejo de errores y reintentos
- IntegraciÃ³n en aplicaciones reales

El SDK abstrae toda la complejidad del flujo de autenticaciÃ³n, gestiÃ³n de tokens y comunicaciÃ³n con el gateway, permitiendo a los desarrolladores enfocarse en la lÃ³gica de su aplicaciÃ³n.

---

## ğŸ‘¥ Sistema de Roles

| Rol | CÃ³digo | TTL Token | Uso |
|-----|--------|-----------|-----|
| **Agent Reasoning** | `AGNR` | 2 min | Agentes con razonamiento complejo |
| **Agent Fast** | `AGNF` | 1 min | Agentes de respuesta rÃ¡pida |
| **AGI** | `AGIA` | 30 min | Sistemas AGI avanzados |
| **User** | `USRS` | 15 min | Usuarios web estÃ¡ndar |
| **Monitoring** | `MNTR` | 20 min | Sistemas de monitoreo |
| **Admin** | `ADMN` | 60 min | Administradores |

---

## ğŸš€ Inicio RÃ¡pido

### 1. InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/Root1V/llm-security.git
cd llm_security

# Instalar dependencias con uv
uv sync
```

### 2. ConfiguraciÃ³n

Crear archivo `.env` con las credenciales de usuarios:

```bash
# Formato: USERNAME=PASSWORD
USRS123ABC=password123
AGNRXYZ456=agentpass456
MNTR789DEF=monitorpass789
```

### 3. Ejecutar el servidor

```bash
uv run dev
```

El servidor estarÃ¡ disponible en: `http://0.0.0.0:9000`

---

## ğŸ“¡ Endpoints API

### `POST /llm/login`
AutenticaciÃ³n para agentes IA (HTTP Basic Auth)

**Roles permitidos:** `agent_reasoning`, `agent_fast`

**Request:**
```bash
curl -X POST http://localhost:9000/llm/login \
  -u "AGNRXYZ456:agentpass456"
```

**Response:**
```json
{
  "token": "eyJhbGciOiJIUzI1NiIs...",
  "expires_in": 1706294400
}
```

### `POST /login`
Login web para usuarios (Form-based)

**Roles permitidos:** `user`, `monitoring`

**Request:**
```bash
curl -X POST http://localhost:9000/login \
  -d "username=USRS123ABC&password=password123"
```

**Response:** RedirecciÃ³n con cookie `auth_token`

### `POST /validate`
ValidaciÃ³n de token para NGINX/Proxy

**Request:**
```json
{
  "token": "eyJhbGciOiJIUzI1NiIs..."
}
```

**Response:**
```json
{
  "valid": true
}
```

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de entorno (`.env`)

```bash

# ConfiguraciÃ³n JWT (opcional en settings.env)
SECRET_KEY=your-secret-key
JWT_ALGORITHM=HS256
TOKEN_CACHE_SIZE=100
TOKEN_TTL_SECONDS=3600
```

### GeneraciÃ³n de credenciales

El sistema incluye una utilidad para generar usuarios y contraseÃ±as:

```bash
uv run python -m security.credentials --generate 5
```

Genera 5 usuarios por cada rol con contraseÃ±as seguras aleatorias.

---

## ğŸ“¦ Estructura del Proyecto

```
llm_security/
â”œâ”€â”€ api/                    # Rutas y endpoints
â”‚   â””â”€â”€ auth_routes.py     # Endpoints de autenticaciÃ³n
â”œâ”€â”€ core/                   # ConfiguraciÃ³n central
â”‚   â”œâ”€â”€ config.py          # Settings con Pydantic
â”‚   â””â”€â”€ dependecies.py     # InyecciÃ³n de dependencias
â”œâ”€â”€ security/               # LÃ³gica de seguridad
â”‚   â”œâ”€â”€ auth.py            # ValidaciÃ³n de credenciales
â”‚   â”œâ”€â”€ tokens.py          # GeneraciÃ³n y validaciÃ³n JWT
â”‚   â””â”€â”€ credentials.py     # GestiÃ³n de usuarios
â”œâ”€â”€ scripts/                # Scripts de automatizaciÃ³n
â”‚   â”œâ”€â”€ dev.py             # Script de desarrollo
â”‚   â””â”€â”€ start.py           # Script de producciÃ³n
â”œâ”€â”€ utils/                  # Utilidades
â”‚   â””â”€â”€ logging_config.py  # ConfiguraciÃ³n de logs
â”œâ”€â”€ main.py                 # Punto de entrada FastAPI
â”œâ”€â”€ pyproject.toml         # ConfiguraciÃ³n del proyecto
â””â”€â”€ .env                    # Credenciales (no versionado)
```

---

## ğŸ› ï¸ TecnologÃ­as

- **FastAPI** - Framework web de alto rendimiento
- **Uvicorn** - Servidor ASGI
- **PyJWT** - GestiÃ³n de tokens JWT
- **Bcrypt** - Hashing de contraseÃ±as
- **Cachetools** - Cache de tokens en memoria
- **Pydantic** - ValidaciÃ³n de configuraciÃ³n
- **uv** - Gestor de paquetes y entornos Python

---

## ğŸ”’ Seguridad

- âœ… AutenticaciÃ³n HTTP Basic para agentes
- âœ… Tokens JWT firmados con HS256
- âœ… TTL diferenciado por rol
- âœ… Cache de tokens con expiraciÃ³n automÃ¡tica
- âœ… ValidaciÃ³n de contraseÃ±as con timing-safe comparison
- âœ… Logs detallados de autenticaciÃ³n
- âš ï¸ En producciÃ³n: habilitar HTTPS y cookies seguras

---

## ğŸ“ Comandos Ãštiles

```bash
# Desarrollo
uv run dev              # Servidor con auto-reload

# ProducciÃ³n
uv run start            # Servidor sin auto-reload

# GestiÃ³n
uv sync                 # Sincronizar dependencias
uv add <paquete>        # Agregar nueva dependencia
```

---

## ğŸ”— IntegraciÃ³n con NGINX

Ejemplo de configuraciÃ³n NGINX para validar tokens:

```nginx
location /llm/ {
    auth_request /auth-validate;
    proxy_pass http://llm-backend:8000/;
}

location = /auth-validate {
    internal;
    proxy_pass http://localhost:9000/validate;
    proxy_pass_request_body off;
    proxy_set_header Content-Length "";
    proxy_set_header X-Original-URI $request_uri;
}
```

---

## ğŸ“„ Licencia

**Licencia de Libre Uso (Free License)**

Este proyecto estÃ¡ disponible bajo una licencia de libre uso. Puedes:
- âœ… Usar el software libremente para cualquier propÃ³sito
- âœ… Modificar el cÃ³digo fuente segÃºn tus necesidades
- âœ… Distribuir copias del software
- âœ… Usar en proyectos comerciales y no comerciales

No se proporciona ninguna garantÃ­a. El software se distribuye "tal cual", sin garantÃ­as de ningÃºn tipo.

## ğŸ‘¨â€ğŸ’» Autor

**Emerice Espiritu Santiago**

- GitHub: [@Root1V](https://github.com/Root1V)
- Proyecto: [llm-security](https://github.com/Root1V/llm-security)

---

**Proyectos Relacionados:**
- [LLM Architecture SDK](https://github.com/Root1V/llm-arch-sdk) - SDK oficial para clientes
- [LLM SDK Client](https://github.com/Root1V/llm-sdk-client) - Ejemplos de uso del SDK
